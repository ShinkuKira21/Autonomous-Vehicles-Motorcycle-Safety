
@misc{dolf_willigers_autopilot_2022,
	type = {Blog},
	title = {Autopilot still kills motorcyclists – {British} {Motorcyclists} {Federation}},
	url = {https://www.britishmotorcyclists.co.uk/autopilot-still-kills-motorcyclists/},
	language = {en-GB},
	urldate = {2023-03-27},
	journal = {Autopilot Still Kills Motorcyclists},
	author = {{Dolf Willigers}},
	month = sep,
	year = {2022},
	file = {Snapshot:/home/skira21/Zotero/storage/SW4JJU9U/autopilot-still-kills-motorcyclists.html:text/html},
}

@misc{govuk_self-driving_2022,
	title = {Self-driving revolution to boost economy and improve road safety},
	url = {https://www.gov.uk/government/news/self-driving-revolution-to-boost-economy-and-improve-road-safety},
	abstract = {New plan for self-driving vehicles plus a consultation on a safety ambition.},
	language = {en},
	urldate = {2023-03-27},
	journal = {Self-driving revolution to boost economy and improve road safety},
	author = {{GOV.UK}},
	month = aug,
	year = {2022},
	file = {Snapshot:/home/skira21/Zotero/storage/MT9LQ5RC/self-driving-revolution-to-boost-economy-and-improve-road-safety.html:text/html},
}

@inproceedings{connected_motorcycle_consortium_applications_nodate,
	title = {Applications to improve rider safety},
	url = {https://www.cmc-info.net/applications.html},
	abstract = {CMC Applications and 'Use cases' described as examples to improve motorcycle safety by means of wireless connectivity between vehicles},
	language = {en},
	urldate = {2023-04-03},
	author = {{Connected Motorcycle Consortium}},
	file = {Snapshot:/home/skira21/Zotero/storage/23UGEKZE/applications.html:text/html},
}

@inproceedings{aecm__the_motorcycle_industry_in_europe_looking_nodate,
	title = {Looking into the future: connected, cooperative and automated mobility},
	url = {https://roadsafetystrategy.acem.eu/home/looking-into-the-future-connected-cooperative-and-automated-mobility/},
	abstract = {The Motorcycle Industry in Europe},
	language = {en-GB},
	urldate = {2023-04-03},
	booktitle = {{ACEM}},
	author = {{aecm {\textbar} The Motorcycle Industry in Europe}},
	file = {Snapshot:/home/skira21/Zotero/storage/Y32YB8MP/looking-into-the-future-connected-cooperative-and-automated-mobility.html:text/html},
}

@misc{deepnets_car_nodate,
	type = {Documentation},
	title = {Car vs {Bike} {Classification} {Dataset}},
	url = {https://www.kaggle.com/datasets/utkarshsaxenadn/car-vs-bike-classification-dataset},
	abstract = {Binary classification task for Car and Bike Classification.},
	language = {en},
	urldate = {2023-04-10},
	journal = {Kaggle {\textbar} Car vs Bike Classification Dataset},
	author = {{Deepnets}},
}

@article{espinosa_motorcycle_2018,
	title = {Motorcycle detection and classification in urban {Scenarios} using a model based on {Faster} {R}-{CNN}},
	url = {http://arxiv.org/abs/1808.02299},
	abstract = {This paper introduces a Deep Learning Convolutional Neural Network model based on Faster-RCNN for motorcycle detection and classification on urban environments. The model is evaluated in occluded scenarios where more than 60\% of the vehicles present a degree of occlusion. For training and evaluation, we introduce a new dataset of 7500 annotated images, captured under real traffic scenes, using a drone mounted camera. Several tests were carried out to design the network, achieving promising results of 75\% in average precision (AP), even with the high number of occluded motorbikes, the low angle of capture and the moving camera. The model is also evaluated on low occlusions datasets, reaching results of up to 92\% in AP.},
	urldate = {2018-08-13},
	journal = {arXiv:1808.02299 [cs]},
	author = {Espinosa, Jorge E. and Velastin, Sergio A. and Branch, John W.},
	month = aug,
	year = {2018},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	annote = {arXiv: 1808.02299},
	annote = {Comment: Presented at 9th International Conference on Pattern Recognition Systems, ICPRS-18, 22-24 May 2018, Valparaiso, Chile},
}

@article{yoo_end--end_2020,
	title = {End-to-{End} {Lane} {Marker} {Detection} via {Row}-wise {Classification}},
	volume = {abs/2005.08630},
	url = {https://arxiv.org/abs/2005.08630},
	journal = {CoRR},
	author = {Yoo, Seungwoo and Lee, Heeseok and Myeong, Heesoo and Yun, Sungrack and Park, Hyoungwoo and Cho, Janghoon and Kim, Duck Hoon},
	year = {2020},
	note = {arXiv: 2005.08630},
}

@article{vandeth_nighttime_2023,
	title = {Nighttime {Motorcycle} {Detection} for {Sparse} {Traffic} {Images} {Using} {Machine} {Learning}},
	volume = {17},
	copyright = {Copyright (c) 2023 Vandeth, Jimmy, Hertog},
	issn = {2460-7010},
	url = {https://journal.binus.ac.id/index.php/commit/article/view/8443},
	doi = {10.21512/commit.v17i1.8443},
	abstract = {Traffic accidents often occur at night. It is understandable, since at night, people have low visibility. Many efforts to develop tools to detect nearby vehicles to avoid crashes have been reported. However, most of them worked only on detecting cars. The research aims to detect motorcycles at night, to complement the previous studies, which mainly focused on cars. The research introduces four features which are extracted from the red pixel and edge map. The algorithm to extract the features has also been developed. They are applied to three commonly used classifiers: Artificial Neural Network (ANN), Decision Tree, and Support Vector Machine (SVM) classifiers to validate the effectiveness of the features. Since the public dataset related to the research is not available yet, the nighttime videos from YouTube have been collected. The datasets contain all the various levels of darkness. They are divided into an 80-20 ratio for training and testing sets to support the experiment and measure the validity of the proposed method. As the best result, the detection using ANN can detect motorcycle proposals with accuracy of 72.71\%, precision of 65.10\% and recall of 73.33\%. Furthermore, during the experiment, the classification can perform consistently in 0.04 seconds per image. Therefore, the method is suitable for use in a real-time system.},
	language = {en},
	number = {1},
	urldate = {2023-04-10},
	journal = {CommIT (Communication and Information Technology) Journal},
	author = {Vandeth, Pov and Tirtawangsa, Jimmy and Nugroho, Hertog},
	month = mar,
	year = {2023},
	note = {Number: 1},
	keywords = {Machine Learning},
	pages = {81--92},
	file = {Full Text PDF:/home/skira21/Zotero/storage/6BDFCXPD/Vandeth et al. - 2023 - Nighttime Motorcycle Detection for Sparse Traffic .pdf:application/pdf},
}

@inproceedings{nava_two-wheeled_2018,
	title = {A two-wheeled vehicle oriented lane detection algorithm},
	doi = {10.1109/ITSC.2018.8569412},
	booktitle = {2018 21st {International} {Conference} on {Intelligent} {Transportation} {Systems} ({ITSC})},
	author = {Nava, Dario and Panzani, Giulio and Zampieri, Pierluigi and Savaresi, Sergio M.},
	year = {2018},
	pages = {423--428},
}

@article{arinaldi_detection_2018,
	title = {Detection and classification of vehicles for traffic video analytics},
	volume = {144},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050918322361},
	doi = {10.1016/j.procs.2018.10.527},
	abstract = {We present a traffic video analysis system based on computer vision techniques. The system is designed to automatically gather important statistics for policy makers and regulators in an automated fashion. These statistics include vehicle counting, vehicle type classification, estimation of vehicle speed from video and lane usage monitoring. The core of such system is the detection and classification of vehicles in traffic videos. We implement two models for this purpose, first is a MoG + SVM system and the second is based on Faster RCNN, a recently popular deep learning architecture for detection of objects in images. We show in our experiments that Faster RCNN outperforms MoG in detection of vehicles that are static, overlapping or in night time conditions. Faster RCNN also outperforms SVM for the task of classifying vehicle types based on appearances.},
	journal = {INNS Conference on Big Data and Deep Learning},
	author = {Arinaldi, Ahmad and Pradana, Jaka Arya and Gurusinga, Arlan Arventa},
	month = jan,
	year = {2018},
	keywords = {Faster RCNN, Traffic Video Analysis, Vehicle Classification, Vehicle Detection},
	pages = {259--268},
}

@inproceedings{jeong_end--end_2017,
	title = {End-to-end learning of image based lane-change decision},
	doi = {10.1109/IVS.2017.7995938},
	abstract = {We propose an image based end-to-end learning framework that helps lane-change decisions for human drivers and autonomous vehicles. The proposed system, Safe Lane-Change Aid Network (SLCAN), trains a deep convolutional neural network to classify the status of adjacent lanes from rear view images acquired by cameras mounted on both sides of the vehicle. Rather than depending on any explicit object detection or tracking scheme, SLCAN reads the whole input image and directly decides whether initiation of the lane-change at the moment is safe or not. We collected and annotated 77,273 rear side view images to train and test SLCAN. Experimental results show that the proposed framework achieves 96.98\% classification accuracy although the test images are from unseen roadways. We also visualize the saliency map to understand which part of image SLCAN looks at for correct decisions.},
	booktitle = {2017 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	author = {Jeong, Seong-Gyun and Kim, Jiwon and Kim, Sujung and Min, Jaesik},
	month = jun,
	year = {2017},
	keywords = {Training, Cameras, Autonomous vehicles, Radar tracking, Roads},
	pages = {1602--1607},
	file = {IEEE Xplore Abstract Record:/home/skira21/Zotero/storage/I9ZPHUB3/7995938.html:text/html;Submitted Version:/home/skira21/Zotero/storage/ZA2QLLT7/Jeong et al. - 2017 - End-to-end learning of image based lane-change dec.pdf:application/pdf},
}

@inproceedings{yu_bdd100k_2020,
	title = {{BDD100K}: {A} {Diverse} {Driving} {Dataset} for {Heterogeneous} {Multitask} {Learning}},
	booktitle = {Proceedings of the {IEEE}/{CVF} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	author = {Yu, Fisher and Chen, Haofeng and Wang, Xin and Xian, Wenqi and Chen, Yingying and Liu, Fangchen and Madhavan, Vashisht and Darrell, Trevor},
	month = jun,
	year = {2020},
}

@inproceedings{cassar_autonomous_2020,
	title = {Autonomous motor vehicle categorisation using a convolutional neural network},
	doi = {10.1109/ICCP51029.2020.9266135},
	abstract = {We present an automatic approach in recognising the classification type of motor vehicles. Over the years, governments and private organisations have implemented schemes in which motor vehicles are categorised according to their size, weight, scale, and axel. Such schemes are used for various purposes, mainly for the implementation of new regulations, generation of statistics as well as urban development. This investigation proposes an autonomous system that is able to detect motorcycles, light motor vehicles (LMV's) and heavy motor vehicles (HMV's) from static images. This was established by training a Convolutional Neural Network (CNN) on preprocessed subsets of an existing dataset using the transfer learning technique. Our model achieved an F1 Score of 94.27\% and an Accuracy Rate of 89.28\% and challenging scenarios were identified.},
	booktitle = {2020 {IEEE} 16th {International} {Conference} on {Intelligent} {Computer} {Communication} and {Processing} ({ICCP})},
	author = {Cassar, Christian Paul and Gatt, Thomas and Briffa, Ivan},
	month = sep,
	year = {2020},
	keywords = {Testing, Training, Artificial Intelligence, Support vector machines, Convolutional Neural Network, Convolutional neural networks, Deep Learning, Image Processing, Motorcycles, Object detection, Vehicle Categorisation., Vehicle detection},
	pages = {337--342},
}

@inproceedings{huynh_convolutional_2016,
	title = {Convolutional neural network for motorbike detection in dense traffic},
	doi = {10.1109/CCE.2016.7562664},
	abstract = {Motorbike detection is not a novel problem. However, as it is not a common vehicle in most countries in the world, there is barely enough research on vision-based methods for motorbike detection, even more so for motorbike detection in dense clusters. In this work, we proposed a detection method that is able to overcome fair occlusions in traffic images. The method is centered around a robust model: the convolutional neural network (CNN) with multiple layers. The CNN model has been proven to achieve state-of-the-art results in multiple vision tasks. Although having a straightforward mechanic, the CNN we constructed is able to achieve positive and stable results throughout a difficult test dataset for motorbike detection.},
	booktitle = {2016 {IEEE} {Sixth} {International} {Conference} on {Communications} and {Electronics} ({ICCE})},
	author = {Huynh, Chi-Kien and Le, Thanh-Sach and Hamamoto, Kazuhiko},
	month = jul,
	year = {2016},
	keywords = {Training, Urban areas, Feature extraction, Support vector machines, Neural networks, Motorcycles},
	pages = {369--374},
}

@inproceedings{padmini_real_2020,
	title = {Real {Time} {Automatic} {Detection} of {Motorcyclists} {With} and {Without} a {Safety} {Helmet}},
	doi = {10.1109/ICOSEC49089.2020.9215415},
	abstract = {In the developing countries like India, the motorcycle riders are increasing day-by-day, wherein it also constitutes to the unprecedented increase in the number of motorcycle accidents across the country. To overcome this drawback, the proposed research work explains and demonstrates a method to enforce better safety protocols through the automatic detection of motorcyclists with and without a safety helmet by using a real-time traffic surveillance footage. The real-time automatic detection of motorcyclists with and without a safety helmet is established through detecting a vehicle and track pipelining it with OpenCV, sklearn, utilizing a descriptor known as the histogram of oriented gradients (HOG), and support vector classification (SVC), which are the combination of tools pertaining to machine learning and image processing mechanisms. With OpenCV Library method, a bike rider is identified in the surveillance video. Further by using a popular machine learning algorithm model called LinearSVC, the classifier label identifies whether the rider is wearing a safety helmet. The data attained in correspondence to the count of bike riders with and without safety helmet is stored in MySQL database with respective timestamps and is also visualized through tabular and graphical views in the developed desktop interface application. With 87.6\% model accuracy, our paper proposes a solution to enhance the existing safety measures and provide a time-efficient approach to handle traffic regulations.},
	booktitle = {2020 {International} {Conference} on {Smart} {Electronics} and {Communication} ({ICOSEC})},
	author = {Padmini, Valanukonda Lakshmi and Kishore, G. Krishna and Durgamalleswarao, Ponnuru and Sree, Parasa Teja},
	month = sep,
	year = {2020},
	keywords = {Real-time systems, Safety, Feature extraction, Machine learning, Support vector machines, Roads, Motorcycles, Accidents, histogram of oriented graphics (HOG), image processing, LinearSVC, MySQL Connector, NumPy, OpenCV, Pandas, sklearn, support vector classification},
	pages = {1251--1256},
	file = {IEEE Xplore Abstract Record:/home/skira21/Zotero/storage/K35PRESQ/9215415.html:text/html},
}

@inproceedings{vishnu_detection_2017,
	title = {Detection of motorcyclists without helmet in videos using convolutional neural network},
	doi = {10.1109/IJCNN.2017.7966233},
	abstract = {In order to ensure the safety measures, the detection of traffic rule violators is a highly desirable but challenging task due to various difficulties such as occlusion, illumination, poor quality of surveillance video, varying whether conditions, etc. In this paper, we present a framework for automatic detection of motorcyclists driving without helmets in surveillance videos. In the proposed approach, first we use adaptive background subtraction on video frames to get moving objects. Later convolutional neural network (CNN) is used to select motorcyclists among the moving objects. Again, we apply CNN on upper one fourth part for further recognition of motorcyclists driving without a helmet. The performance of the proposed approach is evaluated on two datasets, IITH\_Helmet\_1 contains sparse traffic and IITH\_Helmet\_2 contains dense traffic, respectively. The experiments on real videos successfully detect 92.87\% violators with a low false alarm rate of 0.5\% on an average and thus shows the efficacy of the proposed approach.},
	booktitle = {2017 {International} {Joint} {Conference} on {Neural} {Networks} ({IJCNN})},
	author = {Vishnu, C. and Singh, Dinesh and Mohan, C. Krishna and Babu, Sobhan},
	month = may,
	year = {2017},
	note = {ISSN: 2161-4407},
	keywords = {Feature extraction, Videos, Convolutional Neural Network, Neural networks, Deep Learning, Motorcycles, Head, Helmet Detection, Lighting, Surveillance, Traffic Surveillance},
	pages = {3036--3041},
	file = {IEEE Xplore Abstract Record:/home/skira21/Zotero/storage/FWCFYDEH/7966233.html:text/html},
}

@inproceedings{silva_helmet_2014,
	title = {Helmet {Detection} on {Motorcyclists} {Using} {Image} {Descriptors} and {Classifiers}},
	doi = {10.1109/SIBGRAPI.2014.28},
	abstract = {Motorcycle accidents have been rapidly growing throughout the years in many countries. Due to various social and economic factors, this type of vehicle is becoming increasingly popular. The helmet is the main safety equipment of motorcyclists, however many drivers do not use it. The main goal of helmet is to protect the drivers head in case of accident. In case of accident, if the motorcyclist does not use can be fatal. This paper aims to propose a system for detection of motorcyclist without helmet. For this, we have applied the circular Hough transform and the Histogram of Oriented Gradients descriptor to extract the image attributes. Then, the MultiLayer Perceptron classifier was used and the obtained results were compared with others algorithms. Traffic images were captured by cameras from public roads and constitute a database of 255 images. Indeed, the algorithm step regarding the helmet detection accomplished an accuracy rate of 91.37\%.},
	booktitle = {2014 27th {SIBGRAPI} {Conference} on {Graphics}, {Patterns} and {Images}},
	author = {Silva, Romuere Rodrigues Veloso e and Aires, Kelson Rômulo Teixeira and Veras, Rodrigo de Melo Souza},
	month = aug,
	year = {2014},
	note = {ISSN: 2377-5416},
	keywords = {Feature extraction, Accuracy, Histograms, Classification, Motorcycles, Head, Helmet, Image edge detection},
	pages = {141--148},
	file = {IEEE Xplore Abstract Record:/home/skira21/Zotero/storage/CWWVEIDT/6915301.html:text/html},
}

@inproceedings{silva_automatic_2013,
	title = {Automatic detection of motorcyclists without helmet},
	doi = {10.1109/CLEI.2013.6670613},
	abstract = {Motorcycle accidents have been rapidly growing throughout the years in many countries. Due to various social and economic factors, this type of vehicle is becoming increasingly popular. The helmet is the main safety equipment of motorcyclists, but many drivers do not use it. If an motorcyclist is without helmet an accident can be fatal. This paper aims to explain and illustrate an automatic method for motorcycles detection and classification on public roads and a system for automatic detection of motorcyclists without helmet. For this, a hybrid descriptor for features extraction is proposed based in Local Binary Pattern, Histograms of Oriented Gradients and the Hough Transform descriptors. Traffic images captured by cameras were used. The best result obtained from classification was an accuracy rate of 0.9767, and the best result obtained from helmet detection was an accuracy rate of 0.9423.},
	booktitle = {2013 {XXXIX} {Latin} {American} {Computing} {Conference} ({CLEI})},
	author = {Silva, Romuere and Aires, Kelson and Santos, Thiago and Abdala, Kalyf and Veras, Rodrigo and Soares, André},
	month = oct,
	year = {2013},
	keywords = {Feature extraction, Support vector machines, Histograms, Image segmentation, Roads, Motorcycles, helmet detection, hybrid descriptor, motorcycle detection, vehicle classification},
	pages = {1--7},
	file = {IEEE Xplore Abstract Record:/home/skira21/Zotero/storage/4E8ZWZB9/6670613.html:text/html},
}

@article{ionita_autonomous_2017,
	title = {Autonomous vehicles: from paradigms to technology},
	volume = {252},
	issn = {1757-899X},
	url = {https://dx.doi.org/10.1088/1757-899X/252/1/012098},
	doi = {10.1088/1757-899X/252/1/012098},
	abstract = {Mobility is a basic necessity of contemporary society and it is a key factor in global economic development. The basic requirements for the transport of people and goods are: safety and duration of travel, but also a number of additional criteria are very important: energy saving, pollution, passenger comfort.

Due to advances in hardware and software, automation has penetrated massively in transport systems both on infrastructure and on vehicles, but man is still the key element in vehicle driving. However, the classic concept of ‘human-in-the-loop’ in terms of ‘hands on’ in driving the cars is competing aside from the self-driving startups working towards so-called ‘Level 4 autonomy’, which is defined as “a self-driving system that does not requires human intervention in most scenarios”.

In this paper, a conceptual synthesis of the autonomous vehicle issue is made in connection with the artificial intelligence paradigm. It presents a classification of the tasks that take place during the driving of the vehicle and its modeling from the perspective of traditional control engineering and artificial intelligence. The issue of autonomous vehicle management is addressed on three levels: navigation, movement in traffic, respectively effective maneuver and vehicle dynamics control. Each level is then described in terms of specific tasks, such as: route selection, planning and reconfiguration, recognition of traffic signs and reaction to signaling and traffic events, as well as control of effective speed, distance and direction. The approach will lead to a better understanding of the way technology is moving when talking about autonomous cars, smart/intelligent cars or intelligent transport systems. Keywords: self-driving vehicle, artificial intelligence, deep learning, intelligent transport systems.},
	number = {1},
	journal = {IOP Conference Series: Materials Science and Engineering},
	author = {Ionita, Silviu},
	month = oct,
	year = {2017},
	note = {Publisher: IOP Publishing},
	pages = {012098},
}

@inproceedings{connected_motorcycle_consortium_application_2020,
	title = {Application {Specification} {\textbar} {Chapter}: {Lane} {Change} {Warning} / {Blind} {Spot} {Warning} ({LCW}/{BSW})},
	url = {https://www.cmc-info.net/uploads/1/2/1/4/121453783/3.3_-_lcw-bsw_-_use_case_description___technical_description.pdf},
	language = {English},
	urldate = {2023-04-05},
	publisher = {Connected Motorcycle Consortium},
	author = {{Connected Motorcycle Consortium}},
	month = nov,
	year = {2020},
	file = {3.3_-_lcw-bsw_-_use_case_description___technical_description.pdf:/home/skira21/Zotero/storage/WPH6MPBV/3.3_-_lcw-bsw_-_use_case_description___technical_description.pdf:application/pdf},
}

@misc{noauthor_tesla_nodate,
	title = {Tesla {Vision} {Update}: {Replacing} {Ultrasonic} {Sensors} with {Tesla} {Vision} {\textbar} {Tesla} {Support} {United} {Kingdom}},
	shorttitle = {Tesla {Vision} {Update}},
	url = {https://www.tesla.com/en_gb/support/transitioning-tesla-vision},
	abstract = {Safety is at the core of our design and engineering decisions. In 2021, we began our transition to Tesla Vision by removing radar from Model 3 and Model Y, followed by Model S and Model X in 2022. Today, in most regions around the globe, these vehicles now rely on Tesla Vision, our camera-based Autopilot system.},
	language = {en-GB},
	urldate = {2023-04-06},
	journal = {Tesla},
	file = {Snapshot:/home/skira21/Zotero/storage/EHASAU3B/transitioning-tesla-vision.html:text/html},
}

@article{noy_automated_2018,
	title = {Automated driving: {Safety} blind spots},
	volume = {102},
	issn = {0925-7535},
	url = {https://www.sciencedirect.com/science/article/pii/S0925753517304198},
	doi = {https://doi.org/10.1016/j.ssci.2017.07.018},
	abstract = {Driver assist technologies have reached the tipping point and are poised to take control of most, if not all, aspects of the driving task. Proponents of automated driving (AD) are enthusiastic about its promise to transform mobility and realize impressive societal benefits. This paper is an attempt to carefully examine the potential of AD to realize safety benefits, to challenge widely-held assumptions and to delve more deeply into the barriers that are hitherto largely overlooked. As automated vehicle (AV) technologies advance and emerge within a ubiquitous cyber-physical world they raise additional issues that have not yet been adequately defined, let alone researched. Issues around automation, sociotechnical complexity and systems resilience are well known in the context of aviation and space. There are important lessons that could be drawn from these applications to help inform the development of automated driving. This paper argues that for the foreseeable future, regardless of the level of automation, a driver will continue to have a role. It seems clear that the benefits of automated driving, safety and otherwise, will accrue only if these technologies are designed in accordance with sound cybernetics principles, promote effective human-systems integration and gain the trust by operators and the public.},
	journal = {Safety Science},
	author = {Noy, Ian Y. and Shinar, David and Horrey, William J.},
	year = {2018},
	keywords = {Safety, Autonomous vehicles, Automated driving, Driver-vehicle interaction, Psychology},
	pages = {68--78},
}

@article{pammer_they_2021,
	title = {“{They} have to be better than human drivers!” {Motorcyclists}’ and cyclists’ perceptions of autonomous vehicles},
	volume = {78},
	issn = {1369-8478},
	url = {https://www.sciencedirect.com/science/article/pii/S1369847821000334},
	doi = {https://doi.org/10.1016/j.trf.2021.02.009},
	abstract = {Road users and the general population by and large recognise the value of vehicles with automated driving systems and features (otherwise typically known as Autonomous Vehicles (AVs)) in terms of road safety, reduced emissions and convenience, but are still wary of their capability, preferring the ‘comfort zone’ of human operator intervention. Motorcyclists and cyclists conversely, are vulnerable to human fallibility in driving, with the majority of crashes occurring as a consequence of other drivers’ inattention. The transition period associated with the introduction of AVs will require AVs and motorcyclists/cyclists sharing the road for a number of years yet, so we need to understand motorcyclists’/cyclists’ perception of AVs. The question of interest here is whether motorcyclists/cyclists reflect the historical literature in this area by having higher levels of trust for human drivers over AVs, or whether they have higher levels of trust in AVs because it removes the ‘human element’ that has been proven to be particularly dangerous for them. Here we surveyed motorcyclists and cyclists about their trust in human drivers and AVs, and developed a novel suite of questions designed to interrogate the difference between trust in general versus trust as a concept of their own personal safety. Some of the salient outcomes suggest that motorcyclists have medium to low levels of trust for both human drivers and AVs, but are significantly more likely to believe that AVs are safer in terms of their own personal safety, such as prioritising or detecting the rider, compared to human drivers. This relationship varies with age and crash experience. The results here are consistent with the logic that motorcyclists/cyclists have a heightened sense of vulnerability on the road and welcome the introduction of AVs as a way of mitigating personal risk when riding. This insight will be crucial to the subsequent roll-out of AVs in the future.},
	journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
	author = {Pammer, Kristen and Gauld, Cassandra and McKerral, Angus and Reeves, Caitlin},
	year = {2021},
	keywords = {Autonomous vehicles, Cyclists, Human factors psychology, Motorcyclists, Self-drive cars, Vulnerable road users},
	pages = {246--258},
}

@inproceedings{wu_pedestrian_2016,
	title = {Pedestrian, bike, motorcycle, and vehicle classification via deep learning: {Deep} belief network and small training set},
	shorttitle = {Pedestrian, bike, motorcycle, and vehicle classification via deep learning},
	doi = {10.1109/ICASI.2016.7539822},
	abstract = {In traffic monitoring environments where light changes a lot, classifying pedestrians, bikes, motorcycles, and other vehicles quickly is indeed a big challenge. For instance, pedestrians are of variable sizes, bikes of different styles, motorcycles of different shapes, and vehicles of different types. Because of these variations and can influence the classification results for these four categories. Recently, Deep Learning has often been used in object classification with reasonably good results, so interests in researching it for new applications have been aroused. However, Deep Learning is seldom used in researches of classifying pedestrians, bikes, motorcycles, and other vehicles. In this paper, Deep Belief Networks (DBN) of Deep Learning is applied to distinguish the above-mentioned four categories. The proposed DBN methods only used 1,000 image training set and could achieve a higher accuracy of classification rate.},
	booktitle = {2016 {International} {Conference} on {Applied} {System} {Innovation} ({ICASI})},
	author = {Wu, Yen-Yi and Tsai, Chun-Ming},
	month = may,
	year = {2016},
	keywords = {Information science, Instruments, Training, Data collection, Vehicle Classification, Deep Learning, Bike, Decision support systems, Deep Belief Network, Image analysis, Motorcycle, Pattern recognition, Pedestrian, Small Training Set},
	pages = {1--4},
	file = {IEEE Xplore Abstract Record:/home/skira21/Zotero/storage/TF88KG3R/7539822.html:text/html},
}

@article{messelodi_vision-based_2007,
	title = {Vision-based bicycle/motorcycle classification},
	volume = {28},
	issn = {0167-8655},
	url = {https://www.sciencedirect.com/science/article/pii/S0167865507001377},
	doi = {10.1016/j.patrec.2007.04.014},
	abstract = {We present a feature-based classifier that distinguishes bicycles from motorcycles in real-world traffic scenes. The algorithm extracts some visual features focusing on the wheel regions of the vehicles. It splits the problem into two sub-cases depending on the computed motion direction. The classification is performed by non-linear Support Vector Machines. Tests lead to a successful vehicle classification rate of 96.7\% on video sequences taken from different road junctions in an urban environment.},
	language = {en},
	number = {13},
	urldate = {2023-04-12},
	journal = {Pattern Recognition Letters},
	author = {Messelodi, Stefano and Modena, Carla Maria and Cattoni, Gianni},
	month = oct,
	year = {2007},
	keywords = {Feature extraction, Support Vector Machine, Image analysis, Traffic monitoring, Vehicle classification},
	pages = {1719--1726},
	file = {ScienceDirect Full Text PDF:/home/skira21/Zotero/storage/JB7RPDL7/Messelodi et al. - 2007 - Vision-based bicyclemotorcycle classification.pdf:application/pdf;ScienceDirect Snapshot:/home/skira21/Zotero/storage/LFRAFEQT/S0167865507001377.html:text/html},
}

@article{promraksa_lane-filtering_2022,
	title = {Lane-{Filtering} {Behavior} of {Motorcycle} {Riders} at {Signalized} {Urban} {Intersections}},
	volume = {2022},
	issn = {0197-6729},
	url = {https://www.hindawi.com/journals/jat/2022/5662117/},
	doi = {10.1155/2022/5662117},
	abstract = {In developing countries, motorcycle riders typically perform lane filtering at signalized urban intersections. This study aims to determine the factors that affect the lateral clearance of motorcycle riders as they travel between two lanes of mixed traffic at signalized urban intersections in developing countries. In this study, an onboard measurement device was developed to measure the lane-filtering behavior of motorcycle riders. It was installed on a test motorcycle to continuously record the lateral clearance, riding behavior, and surrounding traffic conditions. Thirty participants rode the test motorcycle through a signalized urban intersection. Multilevel linear regression was applied to analyze the relationship between lateral clearance and relevant variables at a significance level of 0.05. The instant speed and side of the filtering motorcycle, condition of the lateral vehicle, type of lateral vehicle, and riding frequency of the motorcycle rider significantly influenced the lateral clearance. The findings of this study can contribute to filtering lane management, connected autonomous vehicles, and microscopic traffic simulations for motorcycles traveling in mixed traffic at signalized urban intersections.},
	language = {en},
	urldate = {2023-04-11},
	journal = {Journal of Advanced Transportation},
	author = {Promraksa, Thanapol and Satiennam, Thaned and Satiennam, Wichuda and Kronprasert, Nopadon},
	month = aug,
	year = {2022},
	note = {Publisher: Hindawi},
	pages = {e5662117},
	file = {Full Text PDF:/home/skira21/Zotero/storage/4C2LABL2/Promraksa et al. - 2022 - Lane-Filtering Behavior of Motorcycle Riders at Si.pdf:application/pdf},
}

@article{miglani_deep_2019,
	title = {Deep learning models for traffic flow prediction in autonomous vehicles: {A} review, solutions, and challenges},
	volume = {20},
	issn = {2214-2096},
	shorttitle = {Deep learning models for traffic flow prediction in autonomous vehicles},
	url = {https://www.sciencedirect.com/science/article/pii/S2214209619302311},
	doi = {10.1016/j.vehcom.2019.100184},
	abstract = {In the last few years, there has been an exponential increase in the usage of the autonomous vehicles across the globe. It is due to an exponential increase in the popularity and usage of the artificial intelligence techniques in various applications. Traffic flow predication is important for autonomous vehicles using which they decide their itinerary and take adaptive decisions (for example, turn let or right, move straight, lane change, stop, or accelerate) with respect to their surrounding objects. From the existing literature, it has been observed that research on autonomous vehicles has shifted from the traditional statistical models to adaptive machine learning techniques. However, existing machine learning models may not be directly applicable in this environment due to non-linear complex relationship between spatial and temporal data collected from the surroundings during the aforementioned adaptive decisions taken by the vehicles. So, with focus on these issues, in this article, we explore various deep learning models for traffic flow prediction in autonomous vehicles and compared these models with respect to their applicability in modern smart transportation systems. Various parameters are chosen to have a relative comparison among different deep learning models. Moreover, challenges and future research directions are also discussed in the article.},
	language = {en},
	urldate = {2023-04-13},
	journal = {Vehicular Communications},
	author = {Miglani, Arzoo and Kumar, Neeraj},
	month = dec,
	year = {2019},
	keywords = {Machine learning, Autonomous vehicles, Cognitive Internet of Things, Deep learning, Traffic flow prediction},
	pages = {100184},
	file = {ScienceDirect Snapshot:/home/skira21/Zotero/storage/5TYRB8WR/S2214209619302311.html:text/html},
}

@article{sharma_analysis_2018,
	title = {An {Analysis} {Of} {Convolutional} {Neural} {Networks} {For} {Image} {Classification}},
	volume = {132},
	issn = {1877-0509},
	url = {https://www.sciencedirect.com/science/article/pii/S1877050918309335},
	doi = {10.1016/j.procs.2018.05.198},
	abstract = {This paper presents an empirical analysis of theperformance of popular convolutional neural networks (CNNs) for identifying objects in real time video feeds. The most popular convolution neural networks for object detection and object category classification from images are Alex Nets, GoogLeNet, and ResNet50. A variety of image data sets are available to test the performance of different types of CNN’s. The commonly found benchmark datasets for evaluating the performance of a convolutional neural network are anImageNet dataset, and CIFAR10, CIFAR100, and MNIST image data sets. This study focuses on analyzing the performance of three popular networks: Alex Net, GoogLeNet, and ResNet50. We have taken three most popular data sets ImageNet, CIFAR10, and CIFAR100 for our study, since, testing the performance of a network on a single data set does not reveal its true capability and limitations. It must be noted that videos are not used as a training dataset, they are used as testing datasets. Our analysis shows that GoogLeNet and ResNet50 are able to recognize objects with better precision compared to Alex Net. Moreover, theperformance of trained CNN’s vary substantially across different categories of objects and we, therefore, will discuss the possible reasons for this.},
	journal = {International Conference on Computational Intelligence and Data Science},
	author = {Sharma, Neha and Jain, Vibhor and Mishra, Anju},
	month = jan,
	year = {2018},
	keywords = {Deep Learning, Object detection, CNN, Neural network, Object classification},
	pages = {377--384},
}

@book{saunders_research_2012,
	edition = {6},
	title = {Research {Methods} for {Business} {Students}},
	publisher = {Pearson Education Limited},
	author = {Saunders, Mark and Lewis, Philip and Thornhill, Adrian},
	year = {2012},
}

@misc{rahman_av_2017,
	title = {{AV} {Survey} {Results} 2017},
	url = {https://bikepgh.org/our-work/advocacy/save/survey/},
	abstract = {Share Tweet The Age of Autonomous Vehicles Background Autonomous Vehicle (AV) companies have been testing autonomous vehicles, and even picking up passengers, on Pittsburgh streets since September 2016 without any high profile incidents. For the most part, citizens and public officials have greeted them (and the AV industry in general) with open arms. Additionally, the},
	language = {en-US},
	urldate = {2023-04-16},
	journal = {BikePGH},
	author = {{Rahman} and {Dey} and {Sherfinski}},
	year = {2017},
	file = {Snapshot:/home/skira21/Zotero/storage/GHZZ9V4Z/survey.html:text/html},
}

@article{pammer_humans_2023,
	title = {Humans vs, machines; motorcyclists and car drivers differ in their opinion and trust of self-drive vehicles},
	volume = {92},
	issn = {1369-8478},
	url = {https://www.sciencedirect.com/science/article/pii/S1369847822002807},
	doi = {10.1016/j.trf.2022.11.014},
	abstract = {Self-drive vehicles have the potential to revolutionise transport systems, however their adoption by mainstream users is highly dependent on a range of factors including trust. Moreover, perceptions of self-drive cars are likely to be highly dependent on the lived-experience of different road user types. Motorcyclists have high impressions of road-vulnerability and distrust for other road users. This distrust stems from the evidence that the vast number of motorcycle crashes occur as a consequence of other-driver error. We therefore hypothesised that compared with car drivers, vulnerable road users such as motorcyclists would report high levels of other-driver distrust, but high levels of trust in self-drive cars. We conducted semi-structured interviews with motorcyclists and car drivers and found that motorcyclists are indeed distrustful of other drivers but have higher levels of trust for self-drive cars compared with car drivers, while car drivers have low levels of trust for self-drive cars, but high levels of trust for other drivers. Motorcyclists were also more likely to report a perspective of trust that centred around their own personal safety on the road. This study provides valuable insights into different road user’s perceptions of AVs.},
	journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
	author = {Pammer, Kristen and Predojevic, Helena and McKerral, Angus},
	month = jan,
	year = {2023},
	keywords = {Autonomous vehicles, Motorcyclists, Self-drive cars, Vulnerable road users, Trust},
	pages = {143--154},
}

@inproceedings{panigrahi_deep_2018,
	title = {Deep {Learning} {Approach} for {Image} {Classification}},
	doi = {10.1109/ICDSBA.2018.00101},
	abstract = {As of late, deep learning has gained remarkable growth in various fields, for example, computer vision and natural language processing. Contrasted with conventional machine learning strategies, deep learning has a robust learning capacity and can improve utilization of datasets for feature extraction. In view of its practicability, deep learning turns out to be increasingly mainstream for many researchers to do research works. In this paper we mainly focus on the optimization of different parameters of convolutional neural network of deep learning for classifying 8000 labelled natural images of cat and dog. First the convolutional neural network is trained to learn features then ANN binary classifier is used for classification. Various level of optimization have been done to improve the performance level of the network and finally, we achieved the best classification accuracy of 88.31\%.},
	booktitle = {2018 2nd {International} {Conference} on {Data} {Science} and {Business} {Analytics} ({ICDSBA})},
	author = {Panigrahi, Santisudha and Nanda, Anuja and Swarnkar, Tripti},
	month = sep,
	year = {2018},
	keywords = {Business, Data science, deep learning, machine learning, neural network, convolutional neural network},
	pages = {511--516},
	file = {IEEE Xplore Abstract Record:/home/skira21/Zotero/storage/EEM5P8N8/8588970.html:text/html},
}

@article{amin_optimizing_2022,
	title = {Optimizing {Convolutional} {Neural} {Networks} with {Transfer} {Learning} for {Making} {Classification} {Report} in {COVID}-19 {Chest} {X}-{Rays} {Scans}},
	volume = {2022},
	issn = {1058-9244},
	url = {https://www.hindawi.com/journals/sp/2022/5145614/},
	doi = {10.1155/2022/5145614},
	abstract = {The coronavirus disease (COVID-19) outbreak, which began in December 2019, has claimed numerous lives and impacted all aspects of human life. COVID-19 was deemed an outbreak by the World Health Organization (WHO) as time passed, putting a tremendous strain on substantially all countries, particularly those with poor health services and delayed reaction times. This recently identified virus is highly contagious. Controlling the rapid spread of this infection requires early detection of infected people through comprehensive screening. For COVID-19 viral diagnosis and follow-up, chest radiography imaging is an excellent tool. Deep learning (DL) has been used for a variety of healthcare purposes, including diabetic retinopathy detection, image classification, and thyroid diagnosis. DL is a useful strategy for combating the COVID-19 outbreak because there are so many streams of medical images (e.g., X-rays, CT, and MRI). In this study, we used the benchmark chest X-ray scan (CXRS) dataset for both COVID-19-infected and noninfected patients. We evaluate the results of DL-based convolutional neural network (CNN) models after preprocessing the scans and using data augmentation. Transfer learning (TL) is used to improve the algorithm’s classification performance for chest radiography imaging. Finally, features of the attention and feature interweave modules are combined to create a more accurate feature map. The architecture is trained for COVID-19 CXRS using CNN, and the newly generated feature layer is applied to TL architecture. The experimental results found that training enhances the CNN + TL algorithm’s ability to classify CXRS with an overall detection accuracy of 99.3\%, precision (0.97), recall (0.98), f-measure (0.98), and receiver operating characteristic (ROC) curve (area = 0.97). The results show that further training improves the classification architecture’s performance by 99.3\%.},
	language = {en},
	urldate = {2023-04-16},
	journal = {Scientific Programming},
	author = {Amin, Samina and Alouffi, Bader and Uddin, M. Irfan and Alosaimi, Wael},
	month = may,
	year = {2022},
	note = {Publisher: Hindawi},
	pages = {e5145614},
	file = {Full Text PDF:/home/skira21/Zotero/storage/XXBXUXEA/Amin et al. - 2022 - Optimizing Convolutional Neural Networks with Tran.pdf:application/pdf},
}

@article{liang_confusion_2022,
	title = {Confusion {Matrix}: {Machine} {Learning}},
	volume = {3},
	copyright = {Copyright (c) 2022 Jingsai Liang},
	shorttitle = {Confusion {Matrix}},
	url = {https://pac.pogil.org/index.php/pac/article/view/304},
	abstract = {This activity focuses on the evaluation of binary classification models using confusion matrix. In model 1, students will learn the table of confusion, which organizes the prediction results in a 2 by 2 matrix. In model 2, students will summarize a group of evaluation quantities based on the confusion matrix, including precision, recall, FPR, and accuracy. Lastly, students will compare the difference between type I and type II errors.
This activity was developed with NSF support through IUSE-1626765. You may request access to this activity via the following link:\&nbsp;IntroCS-POGIL Activity Writing Program.\&nbsp;

Level: Undergraduate
Setting: Classroom
Activity Type: Learning Cycle
Discipline: Computer Science
Course: Machine Learning
Keywords: model evaluation, confusion matrix, precision, recall, accuracy, FPR},
	language = {en},
	number = {4},
	urldate = {2023-04-16},
	journal = {POGIL Activity Clearinghouse},
	author = {Liang, Jingsai},
	month = dec,
	year = {2022},
	note = {Number: 4},
}

@inproceedings{owais_effort_2016,
	title = {Effort, duration and cost estimation in agile software development},
	doi = {10.1109/IC3.2016.7880216},
	booktitle = {2016 {Ninth} {International} {Conference} on {Contemporary} {Computing} ({IC3})},
	author = {Owais, Mohd. and Ramakishore, R.},
	year = {2016},
	pages = {1--5},
}

@inproceedings{john_developing_2020,
	address = {New York, NY, USA},
	series = {{ICSSP} '20},
	title = {Developing {ML}/{DL} {Models}: {A} {Design} {Framework}},
	isbn = {978-1-4503-7512-2},
	url = {https://doi.org/10.1145/3379177.3388892},
	doi = {10.1145/3379177.3388892},
	abstract = {Artificial Intelligence is becoming increasingly popular with organizations due to the success of Machine Learning and Deep Learning techniques. Using these techniques, data scientists learn from vast amounts of data to enhance behaviour in software-intensive systems. Despite the attractiveness of these techniques, however, there is a lack of systematic and structured design process for developing ML/DL models. The study uses a multiple-case study approach to explore the different activities and challenges data scientists face when developing ML/DL models in software-intensive embedded systems. In addition, we have identified seven different phases in the proposed design process leading to effective model development based on the case study. Iterations identified between phases and events which trigger these iterations optimize the design process for ML/DL models. Lessons learned from this study allow data scientists and engineers to develop high-performance ML/DL models and also bridge the gap between high demand and low supply of data scientists.},
	booktitle = {Proceedings of the {International} {Conference} on {Software} and {System} {Processes}},
	publisher = {Association for Computing Machinery},
	author = {John, Meenu Mary and Olsson, Helena Holmström and Bosch, Jan},
	year = {2020},
	note = {event-place: Seoul, Republic of Korea},
	keywords = {Design, Artificial Intelligence, Software Engineering, Machine Learning, Deep Learning},
	pages = {1--10},
}

@article{zhang_overview_2018,
	title = {An overview on {Restricted} {Boltzmann} {Machines}},
	volume = {275},
	issn = {0925-2312},
	url = {https://www.sciencedirect.com/science/article/pii/S0925231217315849},
	doi = {10.1016/j.neucom.2017.09.065},
	abstract = {The Restricted Boltzmann Machine (RBM) has aroused wide interest in machine learning fields during the past decade. This review aims to report the recent developments in theoretical research and applications of the RBM. We first give an overview of the general RBM from the theoretical perspective, including stochastic approximation methods, stochastic gradient methods, and preventing overfitting methods. And then this review focuses on the RBM variants which further improve the learning ability of the RBM under general or specific applications. The RBM has recently been extended for representational learning, document modeling, multi-label learning, weakly supervised learning and many other tasks. The RBM and RBM variants provide powerful tools for representing dependency in the data, and they can be used as the basic building blocks to create deep networks. Apart from the Deep Belief Network (DBN) and the Deep Boltzmann Machine (DBM), the RBM can also be combined with the Convolutional Neural Network (CNN) to create deep networks. This review provides a comprehensive view of these advances in the RBM together with its future perspectives.},
	journal = {Neurocomputing},
	author = {Zhang, Nan and Ding, Shifei and Zhang, Jian and Xue, Yu},
	month = jan,
	year = {2018},
	keywords = {Classification, Deep networks, Representational learning, Restricted Boltzmann Machine},
	pages = {1186--1199},
}

@article{zhao_parallel_2019,
	title = {Parallel computing method of deep belief networks and its application to traffic flow prediction},
	volume = {163},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705118305112},
	doi = {10.1016/j.knosys.2018.10.025},
	abstract = {Deep belief networks (DBNs) with outstanding advantages of learning input data features have attained particular attention and are applied widely in image processing, speech recognition, natural language interpretation, disease diagnosis, among others. However, owing to large data, the training processes of DBNs are time-consuming and may not satisfy the requirements of real-time application systems. In this study, a single dataset is decomposed into multiple subdatasets that are distributed to multiple computing nodes. Multiple computing nodes learn the features of their own subdatasets. On the precondition of the remaining features where one computing node learns from the total dataset, the single dataset learning models and algorithms are extended to the cases where multiple computing nodes learn multiple subdatasets in a parallel manner. Learning models and algorithms are proposed for the parallel computing of DBN learning processes. A master–slave parallel computing structure is designed, where the slave computing nodes learn the features of their respective subdatasets and transmit them to the master computing node. The master computing node is critical in synthesizing the learned features from the respective slave computing nodes. The broadcast, synchronization, and synthesis are repeated until all features of subdatasets have been learned. The proposed parallel computing method is applied to traffic flow prediction using practical traffic flow data. Our experimental results verify the effectiveness of the parallel computing method of DBN learning processes in terms of decreasing pre-training and fine-tuning times and maintaining the prominent feature learning abilities.},
	journal = {Knowledge-Based Systems},
	author = {Zhao, Lu and Zhou, Yonghua and Lu, Huapu and Fujita, Hamido},
	month = jan,
	year = {2019},
	keywords = {Deep learning, Traffic flow prediction, Deep belief network, Parallel computing},
	pages = {972--987},
}

@article{uijlings_selective_2013,
	title = {Selective {Search} for {Object} {Recognition}},
	volume = {104},
	issn = {1573-1405},
	url = {https://doi.org/10.1007/s11263-013-0620-5},
	doi = {10.1007/s11263-013-0620-5},
	abstract = {This paper addresses the problem of generating possible object locations for use in object recognition. We introduce selective search which combines the strength of both an exhaustive search and segmentation. Like segmentation, we use the image structure to guide our sampling process. Like exhaustive search, we aim to capture all possible object locations. Instead of a single technique to generate possible object locations, we diversify our search and use a variety of complementary image partitionings to deal with as many image conditions as possible. Our selective search results in a small set of data-driven, class-independent, high quality locations, yielding 99 \% recall and a Mean Average Best Overlap of 0.879 at 10,097 locations. The reduced number of locations compared to an exhaustive search enables the use of stronger machine learning techniques and stronger appearance models for object recognition. In this paper we show that our selective search enables the use of the powerful Bag-of-Words model for recognition. The selective search software is made publicly available (Software: http://disi.unitn.it/{\textasciitilde}uijlings/SelectiveSearch.html).},
	number = {2},
	journal = {International Journal of Computer Vision},
	author = {Uijlings, J. R. R. and van de Sande, K. E. A. and Gevers, T. and Smeulders, A. W. M.},
	month = sep,
	year = {2013},
	pages = {154--171},
}

@inproceedings{ren_faster_2015,
	title = {Faster {R}-{CNN}: {Towards} {Real}-{Time} {Object} {Detection} with {Region} {Proposal} {Networks}},
	volume = {28},
	url = {https://proceedings.neurips.cc/paper_files/paper/2015/file/14bfa6bb14875e45bba028a21ed38046-Paper.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	publisher = {Curran Associates, Inc.},
	author = {Ren, Shaoqing and He, Kaiming and Girshick, Ross and Sun, Jian},
	editor = {Cortes, C. and Lawrence, N. and Lee, D. and Sugiyama, M. and Garnett, R.},
	year = {2015},
}

@inproceedings{girshick_fast_2015,
	title = {Fast {R}-{CNN}},
	doi = {10.1109/ICCV.2015.169},
	booktitle = {2015 {IEEE} {International} {Conference} on {Computer} {Vision} ({ICCV})},
	author = {Girshick, Ross},
	year = {2015},
	pages = {1440--1448},
}

@misc{govuk_self-driving_2022-1,
	type = {Government {Article}},
	title = {Self-driving revolution to boost economy and improve road safety},
	url = {https://www.gov.uk/government/news/self-driving-revolution-to-boost-economy-and-improve-road-safety},
	abstract = {New plan for self-driving vehicles plus a consultation on a safety ambition.},
	language = {en},
	urldate = {2023-07-21},
	journal = {Self-driving revolution to boost economy and improve road safety},
	author = {{GOV.UK}},
	month = aug,
	year = {2022},
	file = {Snapshot:/home/skira21/Zotero/storage/F3TXLD2Y/self-driving-revolution-to-boost-economy-and-improve-road-safety.html:text/html},
}

@misc{thinkautonomous_computer_2020,
	title = {Computer {Vision} at {Tesla} for {Self}-{Driving} {Cars}},
	url = {https://www.thinkautonomous.ai/blog/computer-vision-at-tesla/},
	abstract = {Recently, Tesla has released "Tesla Vision", their new system equipped only with cameras... making it one of the only companies in the world not to use RADARs!},
	language = {en},
	urldate = {2023-07-21},
	journal = {Welcome to The Library!},
	author = {{ThinkAutonomous}},
	month = jul,
	year = {2020},
	file = {Snapshot:/home/skira21/Zotero/storage/MK63QKGT/computer-vision-at-tesla.html:text/html},
}

@misc{eduonix_real-world_2022,
	title = {Real-{World} {Implementations} {Of} {YOLO} {Algorithm}},
	url = {https://blog.eduonix.com/software-development/real-world-implementations-of-yolo-algorithm/},
	abstract = {YOLO stands for ‘You Only Look Once’ and this algorithm is an excellent object-detection algorithm that uses convolutional neural networks.},
	language = {en-US},
	urldate = {2023-07-21},
	journal = {Eduonix Blog},
	author = {Eduonix, Tutor @},
	month = jan,
	year = {2022},
	file = {Snapshot:/home/skira21/Zotero/storage/UKZCJUTI/real-world-implementations-of-yolo-algorithm.html:text/html},
}

@misc{noauthor_tesla_nodate-1,
	title = {Tesla {Vision} {Update}: {Replacing} {Ultrasonic} {Sensors} with {Tesla} {Vision} {\textbar} {Tesla} {Support} {United} {Kingdom}},
	shorttitle = {Tesla {Vision} {Update}},
	url = {https://www.tesla.com/en_gb/support/transitioning-tesla-vision},
	abstract = {Safety is at the core of our design and engineering decisions. In 2021, we began our transition to Tesla Vision by removing radar from Model 3 and Model Y, followed by Model S and Model X in 2022. Today, in most regions around the globe, these vehicles now rely on Tesla Vision, our camera-based Autopilot system.},
	language = {en-GB},
	urldate = {2023-07-21},
	journal = {Tesla},
	file = {Snapshot:/home/skira21/Zotero/storage/SLCX23A3/transitioning-tesla-vision.html:text/html},
}

@inproceedings{yoshioka_real-time_2017,
	title = {Real-time object classification for autonomous vehicle using {LIDAR}},
	doi = {10.1109/ICIIBMS.2017.8279696},
	abstract = {Object classification is an important issue in order to bring autonomous vehicle into reality. In this paper, real-time and robust classification based on Real AdaBoost algorithm is researched and improved. Various effective features of road objects are computed using LIDAR 3D point clouds. The improved classifier provides an accuracy of over 90 (\%) in a range of 50 (m) and classifies objects into car, pedestrian, bicyclist and background. Moreover, processing time of classifying an object consumes only 0.07×10-3 (sec) that enables this method to be used for autonomous driving on urban roads.},
	booktitle = {2017 {International} {Conference} on {Intelligent} {Informatics} and {Biomedical} {Sciences} ({ICIIBMS})},
	author = {Yoshioka, Masaru and Suganuma, Naoki and Yoneda, Keisuke and Aldibaja, Mohammad},
	month = nov,
	year = {2017},
	note = {ISSN: 2189-8723},
	keywords = {Feature extraction, Three-dimensional displays, Classification algorithms, Autonomous vehicles, Roads, Automobiles, Autonomous Vehicle, Laser radar, LIDAR, Object Classification, Point Cloud, Real AdaBoost},
	pages = {210--211},
	file = {IEEE Xplore Abstract Record:/home/skira21/Zotero/storage/QGWJB2H7/8279696.html:text/html},
}

@article{royo_overview_2019,
	title = {An {Overview} of {Lidar} {Imaging} {Systems} for {Autonomous} {Vehicles}},
	volume = {9},
	copyright = {http://creativecommons.org/licenses/by/3.0/},
	issn = {2076-3417},
	url = {https://www.mdpi.com/2076-3417/9/19/4093},
	doi = {10.3390/app9194093},
	abstract = {Lidar imaging systems are one of the hottest topics in the optronics industry. The need to sense the surroundings of every autonomous vehicle has pushed forward a race dedicated to deciding the final solution to be implemented. However, the diversity of state-of-the-art approaches to the solution brings a large uncertainty on the decision of the dominant final solution. Furthermore, the performance data of each approach often arise from different manufacturers and developers, which usually have some interest in the dispute. Within this paper, we intend to overcome the situation by providing an introductory, neutral overview of the technology linked to lidar imaging systems for autonomous vehicles, and its current state of development. We start with the main single-point measurement principles utilized, which then are combined with different imaging strategies, also described in the paper. An overview of the features of the light sources and photodetectors specific to lidar imaging systems most frequently used in practice is also presented. Finally, a brief section on pending issues for lidar development in autonomous vehicles has been included, in order to present some of the problems which still need to be solved before implementation may be considered as final. The reader is provided with a detailed bibliography containing both relevant books and state-of-the-art papers for further progress in the subject.},
	language = {en},
	number = {19},
	urldate = {2023-08-02},
	journal = {Applied Sciences},
	author = {Royo, Santiago and Ballesta-Garcia, Maria},
	month = jan,
	year = {2019},
	note = {Number: 19
Publisher: Multidisciplinary Digital Publishing Institute},
	keywords = {3D imaging, autonomous vehicles, ladar, lasers, lidar, MEMS, photodetectors, point cloud, scanners, self-driving car, time of flight},
	pages = {4093},
	file = {Full Text PDF:/home/skira21/Zotero/storage/ZFINE7P5/Royo and Ballesta-Garcia - 2019 - An Overview of Lidar Imaging Systems for Autonomou.pdf:application/pdf},
}

@article{li_what_2021,
	title = {What {Happens} for a {ToF} {LiDAR} in {Fog}?},
	volume = {22},
	issn = {1558-0016},
	doi = {10.1109/TITS.2020.2998077},
	abstract = {By transmitting lasers and processing laser returns, LiDAR (light detection and ranging) perceives the surrounding environment through distance measurements. Because of high ranging accuracy, LiDAR is one of the most critical sensors in autonomous driving systems. Revolving around the 3D point clouds generated from LiDARs, plentiful algorithms have been developed for object detection/tracking, environmental mapping, or localization. However, a LiDAR’s ranging performance suffers under adverse weather (e.g. fog, rain, snow etc.), which impedes full autonomous driving in all weather conditions. This article focuses on analyzing the performance of a typical time-of-flight (ToF) LiDAR under fog environment. By controlling the fog density within CEREMA Adverse Weather Facility, the relations between the ranging performance and fogs are both qualitatively and quantitatively investigated. Furthermore, based on the collected data, a machine learning based model is trained to predict the minimum fog visibility that allows successful ranging for this type of LiDAR. The revealed experimental results and methods are helpful for ToF LiDAR specifications from automotive industry.},
	number = {11},
	journal = {IEEE Transactions on Intelligent Transportation Systems},
	author = {Li, You and Duthon, Pierre and Colomb, Michèle and Ibanez-Guzman, Javier},
	month = nov,
	year = {2021},
	note = {Conference Name: IEEE Transactions on Intelligent Transportation Systems},
	keywords = {Rain, Laser radar, autonomous vehicles, adverse weather, Distance measurement, laser noise, Measurement by laser beam, Surface emitting lasers},
	pages = {6670--6681},
	file = {IEEE Xplore Abstract Record:/home/skira21/Zotero/storage/IMHACXCF/9121741.html:text/html},
}

@article{wang_pedestrian_2017,
	title = {Pedestrian recognition and tracking using {3D} {LiDAR} for autonomous vehicle},
	volume = {88},
	issn = {09218890},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0921889015302633},
	doi = {10.1016/j.robot.2016.11.014},
	abstract = {This paper studies the pedestrian recognition and tracking problem for autonomous vehicles using a 3D LiDAR, a classifier trained by SVM (Support Vector Machine) is used to recognize pedestrians, the recognition performance is further improved with the aid of tracking results. By comparing positions and velocity directions of pedestrians with curb information, alarms will be generated if pedestrians are detected to be on road or close to curbs. The proposed approach has been verified on an autonomous vehicle platform.},
	language = {en},
	urldate = {2023-08-02},
	journal = {Robotics and Autonomous Systems},
	author = {Wang, Heng and Wang, Bin and Liu, Bingbing and Meng, Xiaoli and Yang, Guanghong},
	month = feb,
	year = {2017},
	pages = {71--78},
	file = {Wang et al. - 2017 - Pedestrian recognition and tracking using 3D LiDAR.pdf:/home/skira21/Zotero/storage/LFGGMPXE/Wang et al. - 2017 - Pedestrian recognition and tracking using 3D LiDAR.pdf:application/pdf},
}

@misc{roboflow_motorcycle_nodate,
	title = {Motorcycle {Samples} - v1 {VMT}-{V1}},
	url = {https://universe.roboflow.com/workspace-s1xxw/motorcycle-samples/dataset/1},
	abstract = {2000 open source motorcycle images and annotations in multiple formats for training computer vision models. Motorcycle Samples (v1, VMT-V1), created by Workspace},
	language = {en},
	urldate = {2023-08-05},
	journal = {Roboflow},
	author = {{Roboflow}},
	file = {Snapshot:/home/skira21/Zotero/storage/8QJH5FMY/1.html:text/html},
}

@misc{ashfak_yeafi_road_nodate,
	type = {Collection},
	title = {Road {Vehicle} {Images} {Dataset}},
	url = {https://www.kaggle.com/datasets/ashfakyeafi/road-vehicle-images-dataset},
	abstract = {Bangladeshi road vehicle images with YOLO v5 annotation.},
	language = {en},
	urldate = {2023-08-05},
	journal = {Kaggle {\textbar} Road Vehicle Images Dataset},
	author = {{Ashfak Yeafi}},
	file = {Snapshot:/home/skira21/Zotero/storage/RF6RW7EZ/road-vehicle-images-dataset.html:text/html},
}

@misc{govuk_data_2018,
	type = {Legalisation},
	title = {Data {Protection} {Act} 2018},
	url = {https://www.gov.uk/data-protection},
	abstract = {The Data Protection Act (DPA) controls how personal information can be used and your rights to ask for information about yourself},
	language = {en},
	urldate = {2023-08-07},
	journal = {GOV.UK},
	author = {{GOV.UK}},
	month = may,
	year = {2018},
	file = {Snapshot:/home/skira21/Zotero/storage/VINW5XEE/data-protection.html:text/html},
}

@article{pammer_humans_2023-1,
	title = {Humans vs, machines; motorcyclists and car drivers differ in their opinion and trust of self-drive vehicles},
	volume = {92},
	issn = {1369-8478},
	url = {https://www.sciencedirect.com/science/article/pii/S1369847822002807},
	doi = {10.1016/j.trf.2022.11.014},
	abstract = {Self-drive vehicles have the potential to revolutionise transport systems, however their adoption by mainstream users is highly dependent on a range of factors including trust. Moreover, perceptions of self-drive cars are likely to be highly dependent on the lived-experience of different road user types. Motorcyclists have high impressions of road-vulnerability and distrust for other road users. This distrust stems from the evidence that the vast number of motorcycle crashes occur as a consequence of other-driver error. We therefore hypothesised that compared with car drivers, vulnerable road users such as motorcyclists would report high levels of other-driver distrust, but high levels of trust in self-drive cars. We conducted semi-structured interviews with motorcyclists and car drivers and found that motorcyclists are indeed distrustful of other drivers but have higher levels of trust for self-drive cars compared with car drivers, while car drivers have low levels of trust for self-drive cars, but high levels of trust for other drivers. Motorcyclists were also more likely to report a perspective of trust that centred around their own personal safety on the road. This study provides valuable insights into different road user’s perceptions of AVs.},
	language = {en},
	urldate = {2023-08-11},
	journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
	author = {Pammer, Kristen and Predojevic, Helena and McKerral, Angus},
	month = jan,
	year = {2023},
	keywords = {Autonomous vehicles, Motorcyclists, Self-drive cars, Vulnerable road users, Trust},
	pages = {143--154},
	file = {ScienceDirect Full Text PDF:/home/skira21/Zotero/storage/UJBI5GT9/Pammer et al. - 2023 - Humans vs, machines\; motorcyclists and car drivers.pdf:application/pdf;ScienceDirect Snapshot:/home/skira21/Zotero/storage/HQ5R5VU6/S1369847822002807.html:text/html},
}

@article{sankeerthana_strategic_2022,
	title = {A strategic review approach on adoption of autonomous vehicles and its risk perception by road users},
	volume = {7},
	issn = {2364-4184},
	url = {https://doi.org/10.1007/s41062-022-00951-4},
	doi = {10.1007/s41062-022-00951-4},
	abstract = {The adoption of autonomous vehicle (AV) technology is significantly impacted by its potential benefits as well as concerns for the users, which is of interest to researchers and policymakers. However, the users are at risk of involvement due to the failures of technology, which have been given growing attention by many research studies. Hence, it is essential to understand the technology’s acceptance and risk perception by the end users under mixed traffic conditions. This paper aims to provide a review of the studies that involve the perceptions of the public regarding their intention to adopt AVs and the risk-taking behaviour of road users with AVs. In this line, the existing studies are classified based on adoption intention-related studies and public risk perceptions. Further, it is also essential to understand the factors to be considered, survey approach, number of survey samples, and methods adopted by various existing studies in order to understand the future direction related to public adoption intentions of AVs. Moreover, the study identified the factors collected in various studies, which will be helpful to understand which factors are less explored or have a high contribution to the adoption intention of AVs. Furthermore, this study has proposed a methodological framework that paves the way for how to approach studies related to the intention to adopt AVs and contributing factors to the risk perception of AVs. The studies’ insights about survey method, number of samples, methodology to be considered and the contributing factors towards adoption intentions of AV technology are useful to policymakers in developing countries.},
	language = {en},
	number = {6},
	urldate = {2023-08-11},
	journal = {Innovative Infrastructure Solutions},
	author = {Sankeerthana, Gone and Raghuram Kadali, B.},
	month = oct,
	year = {2022},
	keywords = {Autonomous vehicles, Trust, Adoption intention, Behaviour, Developing countries, Risk perception},
	pages = {351},
}

@incollection{bergmann_ethical_2022,
	address = {Cham},
	series = {Studies in {Computational} {Intelligence}},
	title = {Ethical {Issues} in {Automated} {Driving}—{Opportunities}, {Dangers}, and {Obligations}},
	isbn = {978-3-030-77726-5},
	url = {https://doi.org/10.1007/978-3-030-77726-5_5},
	abstract = {Automated vehicles (AVs) not only face questions of technical feasibility but also of moral desirability. Traffic is one of the major sources of death and injury in modern society–human error causing about ninety percent of traffic accidents. Prima facie this yields a strong ethical obligation to further the development and adoption of AVs. However, moral desirability cannot be analyzed solely in terms of increased safety. Broad societal adoption of automated vehicles will entail many ethical issues. One cluster of ethical issues concerns the role of non-human entities occupying positions that usually are reserved for proper moral agents: how should AVs make decisions? And who could be held responsible for their choices? Another cluster of issues concerns the impact widespread adoption of AVs could have on society: which social groups would be negatively affected by the widespread adoption of AVs? Is society becoming too reliant on technology and which potential for abuse is entailed by this dependence? Should citizens remain free to drive vehicles themselves, though they make traffic less safe for everyone? In this paper, I advocate a cautionary position, mindful of the inevitability of technological progress and its great potential, attempting to highlight the obligation to steer this development towards an ethically acceptable trajectory.},
	language = {en},
	urldate = {2023-08-11},
	booktitle = {User {Experience} {Design} in the {Era} of {Automated} {Driving}},
	publisher = {Springer International Publishing},
	author = {Bergmann, Lasse T.},
	editor = {Riener, Andreas and Jeon, Myounghoon and Alvarez, Ignacio},
	year = {2022},
	doi = {10.1007/978-3-030-77726-5_5},
	keywords = {Artificial intelligence, Automated driving, Autonomous driving, AV, Ethical issues, Ethics, Technology},
	pages = {99--121},
}

@misc{govuk_mot_nodate,
	title = {{MOT} inspection manual: motorcycles - 4. {Lamps}, reflectors and electrical equipment - {Guidance} - {GOV}.{UK}},
	shorttitle = {{MOT} inspection manual},
	url = {https://www.gov.uk/guidance/mot-inspection-manual-for-motorcycles/4-lamps-reflectors-and-electrical-equipment},
	abstract = {Headlamp, position lamps, stop lamps, direction indicators, rear registration plate lamp, rear reflector and direction indicator ‘tell-tale’ rules and inspection for motorcycle MOT tests.},
	language = {en},
	urldate = {2023-08-12},
	author = {{GOV.UK}},
	file = {Snapshot:/home/skira21/Zotero/storage/FTHYREMR/4-lamps-reflectors-and-electrical-equipment.html:text/html},
}

@inproceedings{hejase_methodology_2020,
	title = {A {Methodology} for {Model}-{Based} {Validation} of {Autonomous} {Vehicle} {Systems}},
	doi = {10.1109/IV47402.2020.9304603},
	abstract = {The deployment of autonomous vehicles requires safety assurance and performance guarantees of the developed system. However, this is complex due to the number of scenario variations and uncertainty associated with the operating environment. To alleviate this challenge, we propose a model-based validation methodology that relies on a functional hierarchy for the breakdown and simplification of the system navigation functions, and the Backtracking Process Algorithm to identify, trace, and probabilistically quantify risk significant event sequences (scenarios) that lead to Top Events of interest (such as requirement violations). This methodology is demonstrated on a scenario with an occluded pedestrian crossing the road. We are able to identify risks associated with the actor classification problem and sudden changes in behavior of the pedestrian.},
	booktitle = {2020 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	author = {Hejase, Mohammad and Ozguner, Umit and Barbier, Mathieu and Ibanez-Guzman, Javier},
	month = oct,
	year = {2020},
	note = {ISSN: 2642-7214},
	keywords = {Task analysis, Testing, Tools, Safety, Backtracking, Matrix decomposition, Probabilistic logic},
	pages = {2097--2103},
	file = {IEEE Xplore Abstract Record:/home/skira21/Zotero/storage/N5PAMXY3/9304603.html:text/html},
}

@article{katrakazas_new_2019,
	title = {A new integrated collision risk assessment methodology for autonomous vehicles},
	volume = {127},
	journal = {Accident Analysis \& Prevention},
	author = {Katrakazas, Christos and Quddus, Mohammed and Chen, Wen-Hua},
	year = {2019},
	note = {Publisher: Elsevier},
	pages = {61--79},
}

@inproceedings{hejase_validation_2020,
	title = {A {Validation} {Methodology} for the {Minimization} of {Unknown} {Unknowns} in {Autonomous} {Vehicle} {Systems}},
	doi = {10.1109/IV47402.2020.9304616},
	abstract = {Deployment of SAE Level 3+ automated vehicles faces validation and certification challenges due to uncertainty and state space size of the operating domain. We propose a validation and testing methodology that aims to minimize unknown unknowns through minimization of scenarios that have not been accounted for, and scenarios that have not been identified due to modeling deficiencies. The methodology utilizes simulators with different levels of fidelity for residual risk handling, functional hierarchies for simplification of complex navigation tasks, and the Backtracking Process Algorithm to identify scenarios of risk significance. The methodology is demonstrated on a scenario with an intersection preceded by a traffic light. Through use of the testing flowchart, we were able to identify and remedy scenarios leading to undesirable events.},
	booktitle = {2020 {IEEE} {Intelligent} {Vehicles} {Symposium} ({IV})},
	author = {Hejase, Mohammad and Barbier, Mathieu and Ozguner, Umit and Ibanez-Guzman, Javier and Acarman, Tankut},
	month = oct,
	year = {2020},
	note = {ISSN: 2642-7214},
	keywords = {Task analysis, Analytical models, Testing, Backtracking, Minimization, Monte Carlo methods, Uncertainty},
	pages = {114--119},
}

@book{anderson_autonomous_2014,
	title = {Autonomous {Vehicle} {Technology}: {A} {Guide} for {Policymakers}},
	isbn = {978-0-8330-8437-8},
	shorttitle = {Autonomous {Vehicle} {Technology}},
	abstract = {The automotive industry appears close to substantial change engendered by “self-driving” technologies. This technology offers the possibility of significant benefits to social welfare—saving lives; reducing crashes, congestion, fuel consumption, and pollution; increasing mobility for the disabled; and ultimately improving land use. This report is intended as a guide for state and federal policymakers on the many issues that this technology raises.},
	language = {en},
	publisher = {Rand Corporation},
	author = {Anderson, James M. and Nidhi, Kalra and Stanley, Karlyn D. and Sorensen, Paul and Samaras, Constantine and Oluwatola, Oluwatobi A.},
	month = jan,
	year = {2014},
	note = {Google-Books-ID: y0WrAgAAQBAJ},
	keywords = {Technology \& Engineering / Civil / Highway \& Traffic, Transportation / Automotive / General, Transportation / Public Transportation},
}

@misc{govuk_automated_2022,
	type = {Legalisation ({Research})},
	title = {Automated {Vehicles}},
	url = {https://www.lawcom.gov.uk/project/automated-vehicles/},
	abstract = {Documents Summary of automated vehicles: joint report Automated Vehicles: joint report Background Papers Analysis of responses to Consultation Paper 3 All responses to Consultation Paper 3 Impact assessment Overview Overview (Welsh translation)   The project Our work began in 2018 when the Centre for Connected and Autonomous Vehicles (CCAV) asked the Law Commission of England … Read more {\textgreater}},
	language = {en-GB},
	urldate = {2023-09-01},
	journal = {Law Commission},
	author = {{GOV.UK}},
	month = jan,
	year = {2022},
	file = {Snapshot:/home/skira21/Zotero/storage/E3WSQDXM/automated-vehicles.html:text/html},
}

@article{daniello_effectiveness_2009,
	title = {Effectiveness of {Motorcycle} {Training} and {Licensing}},
	volume = {2140},
	issn = {0361-1981},
	url = {https://doi.org/10.3141/2140-23},
	doi = {10.3141/2140-23},
	abstract = {Motorcycle crash fatalities in the United States have been increasing since 1997, when the total number of fatalities reached a record low. Motorcycle training programs were enacted before this rise, and many studies have aimed to show their effectiveness. The objective of this study is to review and synthesize the results of existing research on the effectiveness of motorcycle education courses and different licensing procedures. The effectiveness of programs is examined through the effect training has on accident rates, violation rates, and personal protective equipment use found through past research. Research to date has not consistently supported the notion that training is either effective or ineffective. Some studies have demonstrated that accident and traffic violation rates are lower for trained riders than for untrained riders, whereas others have demonstrated that they are higher for trained riders. Training increases the use of personal protective equipment among motorcyclists. Motorcycle licensing procedures have been shown to have different effects on accident rates. Lower accident rates have been observed in areas with stricter regulations for obtaining a license. The studies vary greatly in both the methods used for comparison and the rigor of their evaluation methodology. No standards for evaluation exist. The findings of these previous studies may be more a reflection of the methods used to evaluate motorcycle training than the effectiveness of training itself.},
	language = {en},
	number = {1},
	urldate = {2023-09-02},
	journal = {Transportation Research Record},
	author = {Daniello, Allison and Gabler, Hampton C. and Mehta, Yusuf A.},
	month = jan,
	year = {2009},
	note = {Publisher: SAGE Publications Inc},
	pages = {206--213},
}

@article{savolainen_effectiveness_2007,
	title = {Effectiveness of {Motorcycle} {Training} and {Motorcyclists}' {Risk}-{Taking} {Behavior}},
	volume = {2031},
	issn = {0361-1981},
	url = {https://doi.org/10.3141/2031-07},
	doi = {10.3141/2031-07},
	abstract = {Persistent increases in motorcycle fatalities and injuries in recent years have heightened safety awareness and have focused attention on the role that motorcyclist training and education can play in reducing accident rates. In this study a 2005 sample of Indiana motorcyclists was used to estimate statistical models of the effectiveness of existing training programs in reducing accident probabilities. Statistical models relating to motorcyclist speed choice and helmet usage behavior were also estimated. The findings showed that those individuals who took beginning rider training courses were more likely to be involved in an accident than those who did not and that those who took the beginning course more than once were much more likely to be involved in an accident. Although explanations for these findings can range from the use of ineffective course material to changes in risk perception as a result of taking the course, another explanation is that riders who take the course are inherently less skilled than those who do not. The findings underscore the need for a careful and comprehensive study of rider skills and risk perceptions to maximize the effectiveness of motorcycle training courses.},
	language = {en},
	number = {1},
	urldate = {2023-09-02},
	journal = {Transportation Research Record},
	author = {Savolainen, Peter and Mannering, Fred},
	month = jan,
	year = {2007},
	note = {Publisher: SAGE Publications Inc},
	pages = {52--58},
}

@article{driving_standards_agency_compulsory_nodate,
	title = {Compulsory {Basic} {Training} ({CBT}) {Assessment} for {Motorcycle} {Instructures}},
	url = {https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/8781/dsa-ia0035812c.pdf},
	journal = {IA/000358/12},
	author = {{Driving Standards Agency} and {GOV.UK}},
	pages = {15},
}

@article{govuk_motorcycle_nodate,
	title = {Motorcycle {License} {Stipulations}},
	url = {https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/1056066/how-to-get-a-motorcycle-licence.pdf},
	urldate = {2023-09-02},
	author = {{GOV.UK}},
	pages = {5},
	file = {how-to-get-a-motorcycle-licence.pdf:/home/skira21/Zotero/storage/H29BBM2G/how-to-get-a-motorcycle-licence.pdf:application/pdf},
}

@misc{govuk_compulsory_2016,
	type = {Legalisation},
	title = {Compulsory basic training ({CBT}) syllabus and guidance notes - {Element} {B}: practical on-site training - {Guidance} - {GOV}.{UK}},
	shorttitle = {Compulsory basic training ({CBT}) syllabus and guidance notes - {Element} {B}},
	url = {https://www.gov.uk/guidance/compulsory-basic-training-cbt-syllabus-and-guidance-notes/element-b-practical-on-site-training},
	abstract = {How the motorcycle or moped works, what maintenance checks are needed, and getting a feel for the weight and balance of the vehicle.},
	language = {en},
	urldate = {2023-09-02},
	journal = {Compulsory basic training (CBT) syllabus and guidance notes - Element B: practical on-site training - Guidance - GOV.UK},
	author = {{GOV.UK}},
	month = dec,
	year = {2016},
	file = {Snapshot:/home/skira21/Zotero/storage/RIQYPSY8/element-b-practical-on-site-training.html:text/html},
}

@misc{govuk_compulsory_2016-1,
	type = {Legalisation},
	title = {Compulsory basic training ({CBT}) syllabus and guidance notes - {Element} {C}: practical on-site riding - {Guidance} - {GOV}.{UK}},
	shorttitle = {Compulsory basic training ({CBT}) syllabus and guidance notes - {Element} {C}},
	url = {https://www.gov.uk/guidance/compulsory-basic-training-cbt-syllabus-and-guidance-notes/element-c-practical-on-site-riding},
	abstract = {Carrying out manoeuvres safely and under full control, using the brakes, changing gear, and carrying out observations.},
	language = {en},
	urldate = {2023-09-02},
	journal = {Compulsory basic training (CBT) syllabus and guidance notes - Element C: practical on-site riding - Guidance - GOV.UK},
	author = {{GOV.UK}},
	month = dec,
	year = {2016},
	file = {Snapshot:/home/skira21/Zotero/storage/DED3Z3Z4/element-c-practical-on-site-riding.html:text/html},
}

@misc{govuk_compulsory_2016-2,
	type = {Legalisation},
	title = {Compulsory basic training ({CBT}) syllabus and guidance notes - {Element} {D}: practical on-road training preparation - {Guidance} - {GOV}.{UK}},
	shorttitle = {Compulsory basic training ({CBT}) syllabus and guidance notes - {Element} {D}},
	url = {https://www.gov.uk/guidance/compulsory-basic-training-cbt-syllabus-and-guidance-notes/element-d-practical-on-road-training-preparation},
	abstract = {Meeting the legal requirements to ride, attitude, positioning, separation distances, speed, anticipating what other road users may do, and preparing for developing hazards.},
	language = {en},
	urldate = {2023-09-02},
	journal = {Compulsory basic training (CBT) syllabus and guidance notes - Element D: practical on-road training preparation - Guidance - GOV.UK},
	author = {{GOV.UK}},
	month = dec,
	year = {2016},
	file = {Snapshot:/home/skira21/Zotero/storage/5F2MU7AY/element-d-practical-on-road-training-preparation.html:text/html},
}

@misc{govuk_compulsory_2016-3,
	type = {Legalisation},
	title = {Compulsory basic training ({CBT}) syllabus and guidance notes - {Element} {E}: practical on-road riding - {Guidance} - {GOV}.{UK}},
	shorttitle = {Compulsory basic training ({CBT}) syllabus and guidance notes - {Element} {E}},
	url = {https://www.gov.uk/guidance/compulsory-basic-training-cbt-syllabus-and-guidance-notes/element-e-practical-on-road-riding},
	abstract = {Riding in typical traffic conditions (including traffic lights, roundabouts, junctions, pedestrian crossings, gradients and bends), and carrying out a u-turn and an emergency stop.},
	language = {en},
	urldate = {2023-09-02},
	journal = {Compulsory basic training (CBT) syllabus and guidance notes - Element E: practical on-road riding - Guidance - GOV.UK},
	author = {{GOV.UK}},
	month = dec,
	year = {2016},
	file = {Snapshot:/home/skira21/Zotero/storage/TLMBNWEC/element-e-practical-on-road-riding.html:text/html},
}
