
@inproceedings{shaha_transfer_2018,
	title = {Transfer {Learning} for {Image} {Classification}},
	doi = {10.1109/ICECA.2018.8474802},
	abstract = {Convolutional neural network (CNN) gained great attention for robust feature extraction and information mining. CNN had been used for variety of applications such as object recognition, image super-resolution, semantic segmentation etc. due to its robust feature extraction and learning mechanism. By keeping constant the baseline learning topology, various CNN architectures were proposed to improve the respective system performance. Among these, AlexNet, VGG16 and VGG19 are the famous CNN architecture introduced for object recognition task. In this paper, we make use of transfer learning to fine-tune the pre-trained network (VGG19) parameters for image classification task. Further, performance of the VGG 19 architecture is compared with AlexNet and VGG16. Along with the CNN architectures, we have compared the hybrid learning approach which is comprised of robust feature extraction from CNN architecture followed by support vector machine (SVM) classifier. We have used two state-of-the-art databases namely: GHIM10K and CalTech256 to study the effect of CNN architecture for robust feature extraction. Performance evaluation has been carried out using average recall, precision and F-score. Performance analysis shows that fine-tuned VGG19 architecture outperforms the other CNN and hybrid learning approach for image classification task.},
	booktitle = {2018 {Second} {International} {Conference} on {Electronics}, {Communication} and {Aerospace} {Technology} ({ICECA})},
	author = {Shaha, Manali and Pawar, Meenakshi},
	month = mar,
	year = {2018},
	keywords = {Conferences, Databases, Task analysis, Computer architecture, Feature extraction, Support vector machines, Image classification, AlexNet, CalTech256, GHIM10K, Robustness, VGG16, VGG19},
	pages = {656--660},
	file = {IEEE Xplore Abstract Record:/home/edwardpatch1/Zotero/storage/S2RA2449/8474802.html:text/html;IEEE Xplore Full Text PDF:/home/edwardpatch1/Zotero/storage/32WTFNKL/Shaha and Pawar - 2018 - Transfer Learning for Image Classification.pdf:application/pdf},
}

@inproceedings{ezerceli_convolutional_2022,
	title = {Convolutional {Neural} {Network} ({CNN}) {Algorithm} {Based} {Facial} {Emotion} {Recognition} ({FER}) {System} for {FER}-2013 {Dataset}},
	doi = {10.1109/ICECCME55909.2022.9988371},
	abstract = {Facial expression recognition (FER) is the key to understanding human emotions and feelings. It is an active area of research since human thoughts can be collected, processed, and used in customer satisfaction, politics, and medical domains. Automated FER systems had been developed and have been used to recognize humans' emotions but it has been a quite challenging problem in machine learning due to the high intra-class variation. The first models were using known methods such as Support Vector Machines (SVM), Bayes classifier, Fuzzy Techniques, Feature Selection, Artificial Neural Networks (ANN) in their models but still, some limitations affect the accuracy critically such as subjectivity, occlusion, pose, low resolution, scale, illumination variation, etc. The ability of CNN boosts FER accuracy. Deep learning algorithms have emerged as the greatest way to produce the best results in FER in recent years. Various datasets were used to train, test, and validate the models. FER2013, CK+, JAFFE and FERG are some of the most popular datasets. To improve the accuracy of FER models, one dataset or a mix of datasets has been employed. Every dataset includes limitations and issues that have an impact on the model that is trained for it. As a solution to this problem, our state-of-the-art model based on deep learning architectures, particularly convolutional neural network architectures (CNN) with supportive techniques has been implemented. The proposed model achieved 93.7 percent accuracy with the combination of FER2013 and CK+ datasets for FER2013.},
	booktitle = {2022 {International} {Conference} on {Electrical}, {Computer}, {Communications} and {Mechatronics} {Engineering} ({ICECCME})},
	author = {Ezerceli, Ozay and Eskil, M. Taner},
	month = nov,
	year = {2022},
	keywords = {Training, Computational modeling, Support vector machines, Emotion recognition, Deep learning, Convolutional neural network, deep learning, emotion detection, Face recognition, facial expression recognition, Mechatronics},
	pages = {1--6},
	file = {IEEE Xplore Abstract Record:/home/edwardpatch1/Zotero/storage/2EBIF265/9988371.html:text/html},
}

@article{kusuma_emotion_2020,
	title = {Emotion recognition on fer-2013 face images using fine-tuned vgg-16},
	volume = {5},
	number = {6},
	journal = {Advances in Science, Technology and Engineering Systems Journal},
	author = {Kusuma, Gede Putra and Jonathan, J and Lim, AP},
	year = {2020},
	pages = {315--322},
}

@inproceedings{singh_deep_2022,
	title = {Deep {Neural} {Network} for {Facial} {Emotion} {Recognition} {System}},
	booktitle = {Computational and {Experimental} {Methods} in {Mechanical} {Engineering}: {Proceedings} of {ICCEMME} 2021},
	publisher = {Springer},
	author = {Singh, Vimal and Gandhi, Sonal and Kumar, Rajiv and Yadav, Ramashankar and Joshi, Shivani},
	year = {2022},
	pages = {397--402},
}

@misc{lin_network_2014,
	title = {Network {In} {Network}},
	url = {http://arxiv.org/abs/1312.4400},
	doi = {10.48550/arXiv.1312.4400},
	abstract = {We propose a novel deep network structure called "Network In Network" (NIN) to enhance model discriminability for local patches within the receptive field. The conventional convolutional layer uses linear filters followed by a nonlinear activation function to scan the input. Instead, we build micro neural networks with more complex structures to abstract the data within the receptive field. We instantiate the micro neural network with a multilayer perceptron, which is a potent function approximator. The feature maps are obtained by sliding the micro networks over the input in a similar manner as CNN; they are then fed into the next layer. Deep NIN can be implemented by stacking mutiple of the above described structure. With enhanced local modeling via the micro network, we are able to utilize global average pooling over feature maps in the classification layer, which is easier to interpret and less prone to overfitting than traditional fully connected layers. We demonstrated the state-of-the-art classification performances with NIN on CIFAR-10 and CIFAR-100, and reasonable performances on SVHN and MNIST datasets.},
	urldate = {2023-04-30},
	publisher = {arXiv},
	author = {Lin, Min and Chen, Qiang and Yan, Shuicheng},
	month = mar,
	year = {2014},
	note = {arXiv:1312.4400 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
	annote = {Comment: 10 pages, 4 figures, for iclr2014},
	file = {arXiv Fulltext PDF:/home/edwardpatch1/Zotero/storage/37GCD35Y/Lin et al. - 2014 - Network In Network.pdf:application/pdf;arXiv.org Snapshot:/home/edwardpatch1/Zotero/storage/EA5MI344/1312.html:text/html},
}

@inproceedings{simonyan_very_2015,
	title = {Very deep convolutional networks for large-scale image recognition},
	booktitle = {3rd {International} {Conference} on {Learning} {Representations}, {ICLR} 2015 - {Conference} {Track} {Proceedings}},
	author = {Simonyan, Karen and Zisserman, Andrew},
	year = {2015},
	pages = {1--14},
}

@inproceedings{krizhevsky_imagenet_2012,
	title = {Imagenet classification with deep convolutional neural networks},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
	author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	year = {2012},
	pages = {1097--1105},
}

@inproceedings{kingma_adam_2015,
	title = {Adam: {A} method for stochastic optimization},
	booktitle = {3rd {International} {Conference} on {Learning} {Representations}, {ICLR} 2015 - {Conference} {Track} {Proceedings}},
	author = {Kingma, Diederik P and Ba, Jimmy},
	year = {2015},
	pages = {1--15},
}

@inproceedings{khemakhem_facial_2019,
	title = {Facial {Expression} {Recognition} using {Convolution} {Neural} {Network} {Enhancing} with {Pre}-{Processing} {Stages}},
	doi = {10.1109/AICCSA47632.2019.9035249},
	abstract = {Recognizing human expression is one of the most popular problems in the Human-Computer Interaction field. Facial Expression Recognition present a great challenge in a wide variety of areas due to varying conditions of the image, which influences expression recognition and makes this task a complex problem. The main difficulties depend on the irregular nature of the human face and the different conditions such as orientation, light and shadows. Lately, Deep learning obtained more attention as an intelligent technology to achieve robustness and offer best performance of expression recognition. Further investigations are still needed in this field in order to make the recognition process very efficient. For that, we present in this paper a new Convolutional Neural Networks model enhancing with pre-processing stages to recognize seven classes (six basic expressions and one neutral). Our approach contains two phases: normalization, and expression recognition. The result can achieve high accuracy compared to recent works with the popular facial expression databases such as CK+, JAFFE, and FER-2013.},
	booktitle = {2019 {IEEE}/{ACS} 16th {International} {Conference} on {Computer} {Systems} and {Applications} ({AICCSA})},
	author = {Khemakhem, Faten and Ltifi, Hela},
	month = nov,
	year = {2019},
	note = {ISSN: 2161-5330},
	keywords = {Databases, Image recognition, Kernel, Feature extraction, Face recognition, Convolutional Neural Networks, Expression Classification, Face, Facial Expression Recognition, Gray-scale, Pre-processing Stages},
	pages = {1--7},
	file = {IEEE Xplore Full Text PDF:/home/edwardpatch1/Zotero/storage/2A7DBV6S/Khemakhem and Ltifi - 2019 - Facial Expression Recognition using Convolution Ne.pdf:application/pdf},
}

@misc{khaireddin_facial_2021,
	title = {Facial {Emotion} {Recognition}: {State} of the {Art} {Performance} on {FER2013}},
	shorttitle = {Facial {Emotion} {Recognition}},
	url = {http://arxiv.org/abs/2105.03588},
	doi = {10.48550/arXiv.2105.03588},
	abstract = {Facial emotion recognition (FER) is significant for human-computer interaction such as clinical practice and behavioral description. Accurate and robust FER by computer models remains challenging due to the heterogeneity of human faces and variations in images such as different facial pose and lighting. Among all techniques for FER, deep learning models, especially Convolutional Neural Networks (CNNs) have shown great potential due to their powerful automatic feature extraction and computational efficiency. In this work, we achieve the highest single-network classification accuracy on the FER2013 dataset. We adopt the VGGNet architecture, rigorously fine-tune its hyperparameters, and experiment with various optimization methods. To our best knowledge, our model achieves state-of-the-art single-network accuracy of 73.28 \% on FER2013 without using extra training data.},
	urldate = {2023-05-01},
	publisher = {arXiv},
	author = {Khaireddin, Yousif and Chen, Zhuofa},
	month = may,
	year = {2021},
	note = {arXiv:2105.03588 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Artificial Intelligence},
	annote = {Comment: 9 pages, 5 figures, 2 tables},
	file = {arXiv Fulltext PDF:/home/edwardpatch1/Zotero/storage/EGLJQ6N5/Khaireddin and Chen - 2021 - Facial Emotion Recognition State of the Art Perfo.pdf:application/pdf;arXiv.org Snapshot:/home/edwardpatch1/Zotero/storage/4UI67PFV/2105.html:text/html},
}

@inproceedings{lan_novel_2020,
	title = {A {Novel} {Industrial} {Intrusion} {Detection} {Method} based on {Threshold}-optimized {CNN}-{BiLSTM}-{Attention} using {ROC} {Curve}},
	doi = {10.23919/CCC50068.2020.9188872},
	abstract = {In recent years, many researchers have proposed many intrusion detection methods to protect the industrial network. However, there are two existing problems among them: one is that they only consider the overall accuracy rate (AC) while ignoring the problem of class imbalance; another one is that they have considered the problem of class imbalance, but the detection rate (DR) is low and false positive rate (FR) is high for minority classes. In order to improve AC and DR of minority classes, we propose a method called threshold-optimized CNN-BiLSTM-Attention that combines CNN-BiLSTM-Attention model, with threshold modification method based on receiver operating characteristic (ROC) curve. In this method, we use CNN-BiLSTM-Attention model as a classifier and modify threshold of the classifier through ROC curve. To evaluate the proposed method, we have performed experiments on the standard industrial data set. And the experimental results show that the proposed method can improve AC and the DR of minority classes at low FR, which is better than other intrusion detection methods.},
	booktitle = {2020 39th {Chinese} {Control} {Conference} ({CCC})},
	author = {Lan, Mindi and Luo, Jun and Chai, Senchun and Chai, Ruiqi and Zhang, Chen and Zhang, Baihai},
	month = jul,
	year = {2020},
	note = {ISSN: 1934-1768},
	keywords = {Standards, Data models, Machine learning algorithms, Intrusion detection, Gray-scale, Class imbalance, CNN-BiLSTM-Attention, Industrial control, Industrial intrusion detection, Numerical models, ROC curve, Threshold modification},
	pages = {7384--7389},
	file = {IEEE Xplore Abstract Record:/home/edwardpatch1/Zotero/storage/FEK7GMVW/9188872.html:text/html;IEEE Xplore Full Text PDF:/home/edwardpatch1/Zotero/storage/QAX5S9UW/Lan et al. - 2020 - A Novel Industrial Intrusion Detection Method base.pdf:application/pdf},
}

@article{sharma_optimised_2021,
	title = {Optimised {CNN} in conjunction with efficient pooling strategy for the multi-classification of breast cancer},
	volume = {15},
	issn = {1751-9667},
	url = {https://onlinelibrary.wiley.com/doi/abs/10.1049/ipr2.12074},
	doi = {10.1049/ipr2.12074},
	abstract = {Tissue analysis using histopathological images is the most prevailing as well as a challenging task in the treatment of cancer. The clinical assessment of tissues becomes very tough as high variability in the magnification levels makes the situation worst for any pathologist to deal with the benign and malignant stages of cancer. One of the possible ways to address such a pathetic situation could be an advanced machine learning approach. Hence, a convolutional neural network (CNN) architecture is proposed to create an automated system for magnification independent multi-classification of breast cancer histopathological images. This automated system offers high productivity and consistency in diagnosing the eight different classes of breast cancer from a balanced BreakHis dataset. The system utilises an efficient training methodology to learn the discerning features from images of different magnification levels. Data augmentation techniques are also employed to overcome the problem of overfitting. Additionally, the performance of CNN architecture has been improved in a significant manner by adopting an appropriate pooling strategy and optimisation technique. Based on that, we have achieved an accuracy of 80.76\%, 76.58\%, 79.90\%, and 74.21\% at the magnification 40X, 100X, 200X, and 400X, respectively. The proposed model outperforms the handcrafted approaches with an average accuracy of 80.47\% at 40X magnification level.},
	language = {en},
	number = {4},
	urldate = {2023-05-01},
	journal = {IET Image Processing},
	author = {Sharma, Shallu and Mehra, Rajesh and Kumar, Sumit},
	year = {2021},
	note = {\_eprint: https://onlinelibrary.wiley.com/doi/pdf/10.1049/ipr2.12074},
	keywords = {Image recognition, and radioactivity, Biology and medical computing, Biomedical measurement and imaging, Computer vision and image processing techniques, health physics, Medical and biomedical uses of fields, Neural nets, Optimisation techniques, Patient diagnostic methods and instrumentation, radiations},
	pages = {936--946},
	file = {Full Text PDF:/home/edwardpatch1/Zotero/storage/VTSCAJMC/Sharma et al. - 2021 - Optimised CNN in conjunction with efficient poolin.pdf:application/pdf;Snapshot:/home/edwardpatch1/Zotero/storage/KY8UAPES/ipr2.html:text/html},
}

@article{miao_recognizing_2019,
	title = {Recognizing facial expressions using a shallow convolutional neural network},
	volume = {7},
	journal = {IEEE access},
	author = {Miao, Si and Xu, Haoyu and Han, Zhenqi and Zhu, Yongxin},
	year = {2019},
	note = {Publisher: IEEE},
	pages = {78000--78011},
}

@inproceedings{joseph_facial_2021,
	title = {Facial {Expression} {Recognition} for the {Blind} {Using} {Deep} {Learning}},
	doi = {10.1109/GUCON50781.2021.9574035},
	abstract = {A large number of people living around us are visually impaired. One of the most difficult tasks faced by them is the identification of the expression of the people in front of them. They are not aware of the intentions and emotions of the other person. Thus a system to assist the blind in recognizing the facial expressions of the confronting person can be of great use. A facial expression recognition system was developed using the convolutional neural network methodology in deep learning. Two models were created for the same. The first model was a proposed CNN architecture trained using FER-2013 dataset. The model could classify the expressions into 7 different classes and obtained an accuracy of 67.18\%. The second model was based on transfer learning approach trained using cleansed FER-2013 dataset. The model could classify the expressions into 4 different classes and obtained an accuracy of 75.55\%. The optimized model of the original transfer learning model was created and deployed on the android device. The model can capture the image of the other person and provide the corresponding class label of expression. The classified text will be then converted to speech for assisting the blind.},
	booktitle = {2021 {IEEE} 4th {International} {Conference} on {Computing}, {Power} and {Communication} {Technologies} ({GUCON})},
	author = {Joseph, Jinu Lilly and Mathew, Santhosh P.},
	month = sep,
	year = {2021},
	keywords = {Conferences, convolutional neural network, Deep learning, Emotion recognition, Face recognition, facial expression recognition, Image recognition, Text recognition, transfer learning, Transfer learning},
	pages = {1--5},
	file = {IEEE Xplore Full Text PDF:/home/edwardpatch1/Zotero/storage/ISVZVNPA/Joseph and Mathew - 2021 - Facial Expression Recognition for the Blind Using .pdf:application/pdf},
}
